{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0736fd4-11e7-4c1f-bb7e-97f2d08f30c7",
   "metadata": {},
   "source": [
    "# building a Logistic machine model using the twitter sentiments datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fad9381-e7af-4b82-aba8-9ddb6acd2693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7824453551912568\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.94      0.87      1835\n",
      "     neutral       0.64      0.48      0.55       620\n",
      "    positive       0.82      0.58      0.68       473\n",
      "\n",
      "    accuracy                           0.78      2928\n",
      "   macro avg       0.76      0.67      0.70      2928\n",
      "weighted avg       0.77      0.78      0.77      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\tumel\\OneDrive\\Desktop\\Twitter US Airline Sentiment\\Tweets.csv\")\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df['text']   # tweets\n",
    "y = df['airline_sentiment']   # sentiment labels\n",
    "\n",
    "# Split data into training & testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Build Logistic Regression Model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f569a-e057-4612-a2b0-4ba5838b9e0c",
   "metadata": {},
   "source": [
    "# building Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7467c06a-a4bb-4a6f-bf2f-fed4de5c9a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7752732240437158\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86      1835\n",
      "     neutral       0.59      0.55      0.57       620\n",
      "    positive       0.75      0.62      0.68       473\n",
      "\n",
      "    accuracy                           0.78      2928\n",
      "   macro avg       0.73      0.69      0.70      2928\n",
      "weighted avg       0.77      0.78      0.77      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\tumel\\OneDrive\\Desktop\\Twitter US Airline Sentiment\\Tweets.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "df['tweet_length'] = df['text'].apply(len)\n",
    "df['num_hashtags'] = df['text'].str.count('#')\n",
    "df['num_mentions'] = df['text'].str.count('@')\n",
    "\n",
    "# Input (X) and Output (y)\n",
    "X_text = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "# Train-test split\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = vectorizer.transform(X_test_text)\n",
    "\n",
    "# Add numeric features\n",
    "X_train_num = df.loc[X_train_text.index, ['tweet_length', 'num_hashtags', 'num_mentions']].values\n",
    "X_test_num = df.loc[X_test_text.index, ['tweet_length', 'num_hashtags', 'num_mentions']].values\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "# Combine text + numeric features\n",
    "X_train_combined = hstack([X_train_vec, X_train_num])\n",
    "X_test_combined = hstack([X_test_vec, X_test_num])\n",
    "\n",
    "# Train Linear Support Vector Classifier\n",
    "model = LinearSVC()\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_combined)\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91014063-1eca-4383-93c2-54217793f980",
   "metadata": {},
   "source": [
    "# building a KNN using the twitter sentiments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13e1fe56-e32a-48c0-a6a3-e0e3ce4819f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7103825136612022\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.89      0.82      1835\n",
      "     neutral       0.55      0.41      0.47       620\n",
      "    positive       0.57      0.41      0.48       473\n",
      "\n",
      "    accuracy                           0.71      2928\n",
      "   macro avg       0.63      0.57      0.59      2928\n",
      "weighted avg       0.69      0.71      0.69      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\tumel\\OneDrive\\Desktop\\Twitter US Airline Sentiment\\Tweets.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "df['tweet_length'] = df['text'].apply(len)\n",
    "df['num_hashtags'] = df['text'].str.count('#')\n",
    "df['num_mentions'] = df['text'].str.count('@')\n",
    "\n",
    "# X = tweet text + meta features\n",
    "X_text = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "# Train-test split\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = vectorizer.transform(X_test_text)\n",
    "\n",
    "# Numeric features\n",
    "X_train_num = df.loc[X_train_text.index, ['tweet_length','num_hashtags','num_mentions']].values\n",
    "X_test_num = df.loc[X_test_text.index, ['tweet_length','num_hashtags','num_mentions']].values\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "# Combine TF-IDF + numeric features\n",
    "X_train_combined = hstack([X_train_vec, X_train_num])\n",
    "X_test_combined = hstack([X_test_vec, X_test_num])\n",
    "\n",
    "# Train KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = knn.predict(X_test_combined)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338ed18-dbc5-40fb-856b-1fcd74c44f28",
   "metadata": {},
   "source": [
    "#RandomForestRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8d94801-01d2-48d7-a2df-9fd99f57d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6598360655737705\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      1.00      0.79      1835\n",
      "     neutral       0.71      0.06      0.11       620\n",
      "    positive       0.88      0.14      0.25       473\n",
      "\n",
      "    accuracy                           0.66      2928\n",
      "   macro avg       0.75      0.40      0.38      2928\n",
      "weighted avg       0.70      0.66      0.56      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\tumel\\OneDrive\\Desktop\\Twitter US Airline Sentiment\\Tweets.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "df['tweet_length'] = df['text'].apply(len)\n",
    "df['num_hashtags'] = df['text'].str.count('#')\n",
    "df['num_mentions'] = df['text'].str.count('@')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X_text = df['text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "# Split dataset\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=3000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = vectorizer.transform(X_test_text)\n",
    "\n",
    "# Numeric features\n",
    "X_train_num = df.loc[X_train_text.index, ['tweet_length','num_hashtags','num_mentions']].values\n",
    "X_test_num = df.loc[X_test_text.index, ['tweet_length','num_hashtags','num_mentions']].values\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "# Combine text + numeric features\n",
    "X_train_combined = hstack([X_train_vec, X_train_num])\n",
    "X_test_combined = hstack([X_test_vec, X_test_num])\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,       # number of trees\n",
    "    max_depth=20,          # limit tree depth\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf.predict(X_test_combined)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425ba91-4f48-4d1c-a83f-08998fd5a707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
